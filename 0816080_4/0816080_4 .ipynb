{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0816080_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNf1ZO4_sJK2"
      },
      "source": [
        "# Assignment 4: CNN\n",
        "\n",
        "## Description\n",
        "\n",
        "Implement a Convolutional Neural Network (CNN) classifier to predict whether a given icon image is the real / fake. Where the fake images were generated by TAs with a neural network.\n",
        "\n",
        "- You are not required to use Colab in this assignment, but you have to **submit your source code**.\n",
        "\n",
        "## Dataset\n",
        "\n",
        "- https://lab.djosix.com/icons.zip\n",
        "- 64x64 RGB jpg images\n",
        "\n",
        "\n",
        "```\n",
        "real/           (10000 images)\n",
        "    0000.jpg\n",
        "    0001.jpg\n",
        "    ...\n",
        "    9999.jpg\n",
        "fake/           (10000 images)\n",
        "    0000.jpg\n",
        "    0001.jpg\n",
        "    ...\n",
        "    9999.jpg\n",
        "unknown/        (5350 images, testing set)\n",
        "    0000.jpg\n",
        "    0001.jpg\n",
        "    ...\n",
        "    5349.jpg\n",
        "```\n",
        "\n",
        "- Training set\n",
        "  - 20000 icons in `real/` and `fake/`\n",
        "  - You should predict 1 for icons in `real/` and 0 for icons in `fake/`\n",
        "- Testing set:\n",
        "  - 5350 icons in `unknown/`\n",
        "  - Your score depends on the **accuracy** on this testing set,  \n",
        "    so the prediction of each icon in `unknown/` should be submitted (totally 5350 predictions, see below).\n",
        "\n",
        "\n",
        "## Submission\n",
        "\n",
        "Please upload **2 files** to E3. (`XXXXXXX` is your student ID)\n",
        "\n",
        "1. **`XXXXXXX_4_result.json`**  \n",
        "  This file contains your model prediction for the testing set.  \n",
        "  You must generate this file with the function called `save_predictions()`.\n",
        "2. **`XXXXXXX_4_source.zip`**  \n",
        "  Zip your source code into this archive.\n",
        "\n",
        "\n",
        "## Hints\n",
        "\n",
        "- **Deep Learning Libraries**: You can use any deep learning frameworks (PyTorch, TensorFlow, ...).\n",
        "- **How to implement**: There are many CNN examples for beginners on the internet, e.g. official websites of the above libraries, play with them and their model architectures to abtain high accuracy on testing set.\n",
        "- **GPU/TPU**: Colab provides free TPU/GPU for training speedup, please refer to [this page in `pytut.pdf` on E3](https://i.imgur.com/VsrUh7I.png).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yuhqE5Chk28",
        "outputId": "e2240170-7df0-413a-85e8-f07d24b0c9b8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j94Kc1dsLaR"
      },
      "source": [
        "### Include this in your code to generate result file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVDRZ6l2h0l0"
      },
      "source": [
        "import keras  \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense ,Dropout\n",
        "from keras.models import Sequential\n",
        "from keras import models\n",
        "from keras.optimizers import Adagrad,RMSprop, SGD, Adam, Nadam\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS7d69dIh1Rz",
        "outputId": "93d117af-6e9a-4d02-bdca-1e5b2ea035be"
      },
      "source": [
        "\n",
        "import os,glob,random\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/hw4.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp\")\n",
        "zip_ref.close()\n",
        "\n",
        "## 取得資料集路徑\n",
        "base_dir = '/tmp'\n",
        "\n",
        "print(os.listdir('/tmp/'))\n",
        "train_path = os.path.join(base_dir, 'train')\n",
        "test_path = os.path.join(base_dir, 'test/unknown')\n",
        "\n",
        "img_list1 = glob.glob(os.path.join(train_path, '*/*.jpg'))\n",
        "\n",
        "print(len(img_list1))\n",
        "\n",
        "img_list2 = glob.glob(os.path.join(test_path, '*/*.jpg'))\n",
        "\n",
        "print(len(img_list2))\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "['tmp6bxyifvb', 'drivefs_ipc.0', 'dap_multiplexer.fddfc81dafa5.root.log.INFO.20210625-060537.51', 'initgoogle_syslog_dir.0', 'train', 'drivefs_ipc.0_shell', 'dap_multiplexer.INFO', 'debugger_11b7zpux0m', 'test']\n",
            "20000\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcqpqG6Gh24C",
        "outputId": "83bfa001-bc3a-4c16-fd6e-e7bfa3f355be"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "# Our input feature map is 150x150x3: 150x150 for the image pixels, and 3 for\n",
        "# the three color channels: R, G, and B\n",
        "img_input = layers.Input(shape=(150, 150, 3))\n",
        "\n",
        "# First convolution extracts 16 filters that are 3x3\n",
        "# Convolution is followed by max-pooling layer with a 2x2 window\n",
        "x = layers.Conv2D(16, 3, activation='relu')(img_input)\n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "\n",
        "# Second convolution extracts 32 filters that are 3x3\n",
        "# Convolution is followed by max-pooling layer with a 2x2 window\n",
        "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "\n",
        "# Third convolution extracts 64 filters that are 3x3\n",
        "# Convolution is followed by max-pooling layer with a 2x2 window\n",
        "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "\n",
        "# Flatten feature map to a 1-dim tensor so we can add fully connected layers\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "# Create a fully connected layer with ReLU activation and 512 hidden units\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "\n",
        "# Create output layer with a single node and sigmoid activation\n",
        "output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create model:\n",
        "# input = input feature map\n",
        "# output = input feature map + stacked convolution/maxpooling layers + fully \n",
        "# connected layer + sigmoid output layer\n",
        "model = Model(img_input, output)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 148, 148, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 18496)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               9470464   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 9,494,561\n",
            "Trainable params: 9,494,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtJkloj5h4gy",
        "outputId": "b767c30a-2b88-429f-9905-0c1b7bcb2b1b"
      },
      "source": [
        "'''\n",
        "這裡用binary_crossentropy損失來訓練模型，因為這個範例是一個二元分類問題，而最終激活函數是sigmoid。 而優化器部份使用rmsprop自動學習速率調速，學習速率初始為0.001。 在訓練期間，需監控分類的準確性。\n",
        "\n",
        "補充說明一下，使用RMSprop優化算法優於隨機梯度下降（SGD），因為RMSprop為我們實現了自動學習速率調整\n",
        "'''\n",
        "\n",
        "\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukbsIy0Xh6ED",
        "outputId": "ff7b636c-484b-4494-d986-70cfb86a6aae"
      },
      "source": [
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.3\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.3\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        ")\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size = (150, 150),\n",
        "    batch_size = 20,\n",
        "    class_mode = 'binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size = (150, 150),\n",
        "    batch_size = 20,\n",
        "    class_mode = 'binary',\n",
        "    shuffle=False,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "labels = (train_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "\n",
        "print(labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14000 images belonging to 2 classes.\n",
            "Found 6000 images belonging to 2 classes.\n",
            "Found 0 images belonging to 0 classes.\n",
            "{0: 'fake', 1: 'real'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDb4BAVCh74c",
        "outputId": "2319409d-0f7f-4609-8bec-0a1e09bdbda1"
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=300,  \n",
        "      epochs=30,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=150,\n",
        "      verbose=2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "300/300 - 50s - loss: 0.7606 - acc: 0.5657 - val_loss: 0.6241 - val_acc: 0.8117\n",
            "Epoch 2/30\n",
            "300/300 - 6s - loss: 0.6586 - acc: 0.6305 - val_loss: 0.1674 - val_acc: 0.9823\n",
            "Epoch 3/30\n",
            "300/300 - 6s - loss: 0.6172 - acc: 0.6652 - val_loss: 0.7365 - val_acc: 0.4280\n",
            "Epoch 4/30\n",
            "300/300 - 6s - loss: 0.5943 - acc: 0.6828 - val_loss: 0.6095 - val_acc: 0.6620\n",
            "Epoch 5/30\n",
            "300/300 - 6s - loss: 0.5564 - acc: 0.7205 - val_loss: 0.6294 - val_acc: 0.6863\n",
            "Epoch 6/30\n",
            "300/300 - 6s - loss: 0.5545 - acc: 0.7233 - val_loss: 0.5377 - val_acc: 0.7667\n",
            "Epoch 7/30\n",
            "300/300 - 6s - loss: 0.5371 - acc: 0.7333 - val_loss: 0.4492 - val_acc: 0.8103\n",
            "Epoch 8/30\n",
            "300/300 - 6s - loss: 0.5296 - acc: 0.7390 - val_loss: 0.5068 - val_acc: 0.8057\n",
            "Epoch 9/30\n",
            "300/300 - 6s - loss: 0.4974 - acc: 0.7560 - val_loss: 0.6204 - val_acc: 0.7193\n",
            "Epoch 10/30\n",
            "300/300 - 6s - loss: 0.4836 - acc: 0.7720 - val_loss: 0.5777 - val_acc: 0.7400\n",
            "Epoch 11/30\n",
            "300/300 - 6s - loss: 0.4527 - acc: 0.7895 - val_loss: 0.2979 - val_acc: 0.9153\n",
            "Epoch 12/30\n",
            "300/300 - 6s - loss: 0.4276 - acc: 0.8053 - val_loss: 0.4410 - val_acc: 0.8020\n",
            "Epoch 13/30\n",
            "300/300 - 6s - loss: 0.4066 - acc: 0.8132 - val_loss: 0.4384 - val_acc: 0.8377\n",
            "Epoch 14/30\n",
            "300/300 - 6s - loss: 0.3733 - acc: 0.8365 - val_loss: 0.4220 - val_acc: 0.8157\n",
            "Epoch 15/30\n",
            "300/300 - 6s - loss: 0.3584 - acc: 0.8483 - val_loss: 0.3786 - val_acc: 0.8363\n",
            "Epoch 16/30\n",
            "300/300 - 6s - loss: 0.3458 - acc: 0.8503 - val_loss: 1.4088 - val_acc: 0.7460\n",
            "Epoch 17/30\n",
            "300/300 - 6s - loss: 0.3326 - acc: 0.8555 - val_loss: 0.1514 - val_acc: 0.9513\n",
            "Epoch 18/30\n",
            "300/300 - 6s - loss: 0.3125 - acc: 0.8667 - val_loss: 0.7143 - val_acc: 0.6983\n",
            "Epoch 19/30\n",
            "300/300 - 6s - loss: 0.2954 - acc: 0.8770 - val_loss: 0.7437 - val_acc: 0.6230\n",
            "Epoch 20/30\n",
            "300/300 - 6s - loss: 0.3071 - acc: 0.8768 - val_loss: 0.2321 - val_acc: 0.9237\n",
            "Epoch 21/30\n",
            "300/300 - 6s - loss: 0.2814 - acc: 0.8803 - val_loss: 0.0781 - val_acc: 0.9817\n",
            "Epoch 22/30\n",
            "300/300 - 6s - loss: 0.2563 - acc: 0.9010 - val_loss: 0.1883 - val_acc: 0.9373\n",
            "Epoch 23/30\n",
            "300/300 - 6s - loss: 0.2476 - acc: 0.8997 - val_loss: 0.4637 - val_acc: 0.7853\n",
            "Epoch 24/30\n",
            "300/300 - 6s - loss: 0.2321 - acc: 0.9065 - val_loss: 0.1573 - val_acc: 0.9593\n",
            "Epoch 25/30\n",
            "300/300 - 6s - loss: 0.2513 - acc: 0.9068 - val_loss: 0.1818 - val_acc: 0.9293\n",
            "Epoch 26/30\n",
            "300/300 - 6s - loss: 0.2100 - acc: 0.9218 - val_loss: 0.2324 - val_acc: 0.9387\n",
            "Epoch 27/30\n",
            "300/300 - 6s - loss: 0.2116 - acc: 0.9230 - val_loss: 0.2211 - val_acc: 0.9303\n",
            "Epoch 28/30\n",
            "300/300 - 6s - loss: 0.1974 - acc: 0.9302 - val_loss: 0.9950 - val_acc: 0.7257\n",
            "Epoch 29/30\n",
            "300/300 - 6s - loss: 0.2124 - acc: 0.9202 - val_loss: 0.9690 - val_acc: 0.6627\n",
            "Epoch 30/30\n",
            "300/300 - 6s - loss: 0.2128 - acc: 0.9342 - val_loss: 0.1113 - val_acc: 0.9727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IODPxERlgrV7"
      },
      "source": [
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "data=[]\n",
        "\n",
        "file=os.listdir(test_path)\n",
        "file.sort()\n",
        "\n",
        "\n",
        "for i in file:\n",
        "  if i.endswith('.jpg'):\n",
        "    #load img\n",
        "    image = load_img(test_path+'/'+i,target_size=(150,150))\n",
        "    #change color(0~255) to (0~1)\n",
        "    image = img_to_array(image).astype('float32')/255\n",
        "    data.append(image)\n",
        "\n",
        "data=np.array(data)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUgYOZfUMvxl"
      },
      "source": [
        "import json\n",
        "\n",
        "def save_predictions(student_id, predictions):\n",
        "  # Please use this function to generate 'XXXXXXX_4_result.json'\n",
        "  # `predictions` is a list of int (0 or 1; fake=0 and real=1)\n",
        "  # For example, `predictions[0]` is the prediction given \"unknown/0000.jpg\".\n",
        "  # it will be 1 if your model think it is real, else 0 (fake).\n",
        "\n",
        "  assert isinstance(student_id, str)\n",
        "  assert isinstance(predictions, list)\n",
        "  assert len(predictions) == 5350\n",
        "\n",
        "  for y in predictions:\n",
        "    assert y in (0, 1)\n",
        "\n",
        "  with open('{}_4_result.json'.format(student_id), 'w') as f:\n",
        "    json.dump(predictions, f)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma9MCRwah-3j"
      },
      "source": [
        "predicts = model.predict(data)\n",
        "predictions = [round(predicts[i][0]) for i in range(len(predicts))]\n",
        "save_predictions('0816080', predictions)"
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}